{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81743f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from euler import EulerPeriodicDataset\n",
    "\n",
    "h5_path = \"/work/imos/datasets/euler_multi_quadrants_periodicBC/data/train/euler_multi_quadrants_periodicBC_gamma_1.76_Ar_-180.hdf5\"\n",
    "stats_path = \"/work/imos/datasets/euler_multi_quadrants_periodicBC/stats.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9133bf74",
   "metadata": {},
   "source": [
    "### 1) Full-grid dataset checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfca383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Full-grid dataset ===\n",
      "EulerPeriodicDataset: using full-grid samples (512x512), this is large (262144 nodes). Consider patching.\n",
      "Dataset created: 40000\n",
      "len(dataset) = 40000\n",
      "n_sims, n_t, H, W = 400 101 512 512\n",
      "n_per_sim = 100 total_samples = 40000\n",
      "static cache keys: ['pos_template', 'x_coords', 'y_coords', 'gamma', 'x_periodic_mask', 'y_periodic_mask', 'x_periodic', 'y_periodic']\n",
      "x_periodic, y_periodic: True True\n",
      "gamma: 1.7599999904632568\n",
      "pos_template shape: (262144, 2)\n",
      "density shape: (1, 512, 512)\n",
      "momentum shape: (1, 512, 512, 2)\n",
      "\n",
      "Built Data object in 5.1s\n",
      "data.x shape (N, C): torch.Size([262144, 5])\n",
      "data.pos shape: torch.Size([262144, 2])\n",
      "edge_index shape: torch.Size([2, 1048576])\n",
      "edge_attr shape: torch.Size([1048576, 4])\n",
      "global features u: tensor([[1.7600, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Full-grid dataset ===\")\n",
    "ds_full = EulerPeriodicDataset(h5_path, stats_path=stats_path, time_window=1, patch_size=None, normalize=True)\n",
    "print(\"Dataset created:\", len(ds_full))\n",
    "\n",
    "# basic metadata checks\n",
    "print(\"len(dataset) =\", len(ds_full))\n",
    "print(\"n_sims, n_t, H, W =\", ds_full.n_sims, ds_full.n_t, ds_full.H, ds_full.W)\n",
    "print(\"n_per_sim =\", ds_full.n_per_sim, \"total_samples =\", ds_full.total_samples)\n",
    "\n",
    "# static cache checks\n",
    "print(\"static cache keys:\", list(ds_full._static_cache.keys()))\n",
    "print(\"x_periodic, y_periodic:\", ds_full._static_cache.get(\"x_periodic\"), ds_full._static_cache.get(\"y_periodic\"))\n",
    "print(\"gamma:\", ds_full._static_cache.get(\"gamma\"))\n",
    "print(\"pos_template shape:\", ds_full._static_cache.get(\"pos_template\").shape)\n",
    "\n",
    "# fast I/O test: load arrays only (no edge build)\n",
    "arrs = ds_full._load_time_window(sim_idx=0, t_idx=0)\n",
    "print(\"density shape:\", arrs[\"density\"].shape)   # expect (time_window, H, W)\n",
    "print(\"momentum shape:\", arrs[\"momentum\"].shape) # expect (time_window, H, W, 2)\n",
    "\n",
    "# build the graph for a single sample (this triggers edge construction, may take a few seconds and memory)\n",
    "t0 = time.time()\n",
    "data = ds_full[0]   # full-grid graph\n",
    "t1 = time.time()\n",
    "print(\"\\nBuilt Data object in {:.1f}s\".format(t1-t0))\n",
    "print(\"data.x shape (N, C):\", data.x.shape)\n",
    "print(\"data.pos shape:\", data.pos.shape)\n",
    "print(\"edge_index shape:\", data.edge_index.shape)\n",
    "print(\"edge_attr shape:\", data.edge_attr.shape)\n",
    "print(\"global features u:\", data.u)\n",
    "\n",
    "# simple assert to ensure original behaviour returns full-grid-size nodes\n",
    "N_full = ds_full.H * ds_full.W\n",
    "assert data.x.shape[0] == N_full, \"Full-grid Data node count mismatch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15ad2c",
   "metadata": {},
   "source": [
    "### 2) Patched dataset checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d928cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Patch-enabled dataset: mapping & decode tests ===\n",
      "patch_size: (64, 64)\n",
      "patch_stride (h,w): 32 32 32\n",
      "patches_per_row, patches_per_col: 15 15\n",
      "patches_per_timestep: 225\n",
      "n_sims, n_per_sim: 400 100\n",
      "expected patches_per_row: 15 col: 15\n",
      "expected patches_per_timestep: 225\n",
      "dataset.total_samples: 9000000 expected: 9000000\n",
      "len(dataset): 9000000\n",
      "per_timestep (patches per timestep): 225 per_sim: 22500\n",
      "idx 0 -> 0 0 0 0\n",
      "idx 22499 -> 0 99 448 448\n",
      "idx 22500 -> 1 0 0 0\n",
      "last idx 8999999 -> sim 399, t 99, i0 448, j0 448\n",
      "\n",
      "✅ Mapping & decode tests passed.\n",
      "\n",
      "=== Cache behaviour test ===\n",
      "Expected patch cache key: edge_patch_64_64_1_1\n",
      "initially in static_cache: []\n",
      "Built first patch in 0.069s\n",
      "after building one patch, cached keys: ['edge_patch_64_64_1_1']\n",
      "edge_index same object: True\n",
      "edge_attr  same object: True\n",
      "Rebuild (no cache key) took 0.052s\n",
      "rebuild returned different edge_index object: True\n",
      "\n",
      "✅ Cache tests passed.\n",
      "\n",
      "=== DataLoader batching test ===\n",
      "Batch.x shape: torch.Size([8192, 5])\n",
      "Batch.pos shape: torch.Size([8192, 2])\n",
      "Batch.batch shape: torch.Size([8192])\n",
      "\n",
      "✅ DataLoader batching test passed.\n",
      "\n",
      "All patch-related tests completed successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Patch-enabled dataset: mapping & decode tests ===\")\n",
    "# choose patch size 64 (cells)\n",
    "patch_size = (64, 64)\n",
    "ds_patch = EulerPeriodicDataset(\n",
    "    h5_path,\n",
    "    stats_path=stats_path,\n",
    "    time_window=1,\n",
    "    patch_size=patch_size,\n",
    "    patch_stride=32,\n",
    "    normalize=True,\n",
    ")\n",
    "\n",
    "# dataset should have computed patches_per_row/col and patches_per_timestep (patches_per_sim)\n",
    "print(\"patch_size:\", ds_patch.patch_size)\n",
    "print(\"patch_stride (h,w):\", ds_patch.patch_stride, ds_patch.patch_stride_h, ds_patch.patch_stride_w)\n",
    "print(\"patches_per_row, patches_per_col:\", ds_patch.patches_per_row, ds_patch.patches_per_col)\n",
    "print(\"patches_per_timestep:\", ds_patch.patches_per_timestep)\n",
    "print(\"n_sims, n_per_sim:\", ds_patch.n_sims, ds_patch.n_per_sim)\n",
    "\n",
    "# expected counts\n",
    "expected_patches_per_row = (ds_patch.W - patch_size[1]) // ds_patch.patch_stride_w + 1\n",
    "expected_patches_per_col = (ds_patch.H - patch_size[0]) // ds_patch.patch_stride_h + 1\n",
    "expected_patches_per_timestep = expected_patches_per_row * expected_patches_per_col\n",
    "expected_total_samples = ds_patch.n_sims * ds_patch.n_per_sim * expected_patches_per_timestep\n",
    "\n",
    "print(\"expected patches_per_row:\", expected_patches_per_row, \"col:\", expected_patches_per_col)\n",
    "print(\"expected patches_per_timestep:\", expected_patches_per_timestep)\n",
    "print(\"dataset.total_samples:\", ds_patch.total_samples, \"expected:\", expected_total_samples)\n",
    "print(\"len(dataset):\", len(ds_patch))\n",
    "\n",
    "# assertions\n",
    "assert ds_patch.patches_per_row == expected_patches_per_row\n",
    "assert ds_patch.patches_per_col == expected_patches_per_col\n",
    "assert ds_patch.patches_per_timestep == expected_patches_per_timestep\n",
    "assert ds_patch.total_samples == expected_total_samples\n",
    "assert len(ds_patch) == expected_total_samples\n",
    "\n",
    "# test _decode_index for several important indices\n",
    "per_timestep = ds_patch.patches_per_timestep\n",
    "per_sim = ds_patch.n_per_sim * per_timestep\n",
    "print(\"per_timestep (patches per timestep):\", per_timestep, \"per_sim:\", per_sim)\n",
    "\n",
    "# first index\n",
    "sim0, t0, i0, j0 = ds_patch._decode_index(0)\n",
    "print(\"idx 0 ->\", sim0, t0, i0, j0)\n",
    "assert sim0 == 0 and t0 == 0\n",
    "\n",
    "# last index in first sim\n",
    "idx_last_first_sim = per_sim - 1\n",
    "sim_l, t_l, i_l, j_l = ds_patch._decode_index(idx_last_first_sim)\n",
    "print(f\"idx {idx_last_first_sim} ->\", sim_l, t_l, i_l, j_l)\n",
    "assert sim_l == 0 and (0 <= t_l < ds_patch.n_per_sim)\n",
    "\n",
    "# first index of second sim\n",
    "idx_per_sim = per_sim\n",
    "sim2, t2, i2, j2 = ds_patch._decode_index(idx_per_sim)\n",
    "print(f\"idx {idx_per_sim} ->\", sim2, t2, i2, j2)\n",
    "assert sim2 == 1 and t2 == 0\n",
    "\n",
    "# last global index\n",
    "idx_last = ds_patch.total_samples - 1\n",
    "sim_last, t_last, i_last, j_last = ds_patch._decode_index(idx_last)\n",
    "print(f\"last idx {idx_last} -> sim {sim_last}, t {t_last}, i0 {i_last}, j0 {j_last}\")\n",
    "assert sim_last == ds_patch.n_sims - 1\n",
    "assert 0 <= t_last < ds_patch.n_per_sim\n",
    "\n",
    "print(\"\\n✅ Mapping & decode tests passed.\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# A) CACHE TESTS\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"=== Cache behaviour test ===\")\n",
    "\n",
    "p_h, p_w = ds_patch.patch_size\n",
    "x_periodic = int(bool(ds_patch._static_cache.get(\"x_periodic\", False)))\n",
    "y_periodic = int(bool(ds_patch._static_cache.get(\"y_periodic\", False)))\n",
    "edge_cache_key = f\"edge_patch_{p_h}_{p_w}_{x_periodic}_{y_periodic}\"\n",
    "\n",
    "print(\"Expected patch cache key:\", edge_cache_key)\n",
    "print(\"initially in static_cache:\", [k for k in ds_patch._static_cache.keys() if 'edge' in k])\n",
    "\n",
    "# Trigger one patch build (calls cached builder)\n",
    "t0 = time.time()\n",
    "data0 = ds_patch[0]\n",
    "t1 = time.time()\n",
    "print(f\"Built first patch in {t1-t0:.3f}s\")\n",
    "\n",
    "print(\"after building one patch, cached keys:\", [k for k in ds_patch._static_cache.keys() if 'edge' in k])\n",
    "assert edge_cache_key in ds_patch._static_cache, \"edge cache key not found after building a patch\"\n",
    "\n",
    "cached = ds_patch._static_cache[edge_cache_key]\n",
    "edge_index_cached = cached[\"edge_index\"]\n",
    "edge_attr_cached = cached[\"edge_attr\"]\n",
    "\n",
    "# call builder again with same cache key -> should return same objects\n",
    "edge_index2, edge_attr2 = ds_patch._build_grid_edges(\n",
    "    p_h, p_w,\n",
    "    data0.pos.reshape(p_h, p_w, 2),\n",
    "    x_periodic=bool(x_periodic),\n",
    "    y_periodic=bool(y_periodic),\n",
    "    cache_key=edge_cache_key,\n",
    ")\n",
    "print(\"edge_index same object:\", edge_index2 is edge_index_cached)\n",
    "print(\"edge_attr  same object:\", edge_attr2 is edge_attr_cached)\n",
    "assert edge_index2 is edge_index_cached and edge_attr2 is edge_attr_cached\n",
    "\n",
    "# rebuild without cache key to confirm difference\n",
    "t0 = time.time()\n",
    "edge_index_new, edge_attr_new = ds_patch._build_grid_edges(\n",
    "    p_h, p_w,\n",
    "    data0.pos.reshape(p_h, p_w, 2),\n",
    "    x_periodic=bool(x_periodic),\n",
    "    y_periodic=bool(y_periodic),\n",
    "    cache_key=None,\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Rebuild (no cache key) took {t1-t0:.3f}s\")\n",
    "print(\"rebuild returned different edge_index object:\", edge_index_new is not edge_index_cached)\n",
    "\n",
    "print(\"\\n✅ Cache tests passed.\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# B) SIMPLE DATALOADER TEST\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"=== DataLoader batching test ===\")\n",
    "\n",
    "num_check = 8\n",
    "idxs = list(range(min(num_check, len(ds_patch))))\n",
    "subset = Subset(ds_patch, idxs)\n",
    "\n",
    "loader = DataLoader(subset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(\"Batch.x shape:\", batch.x.shape)\n",
    "print(\"Batch.pos shape:\", batch.pos.shape)\n",
    "print(\"Batch.batch shape:\", batch.batch.shape)\n",
    "\n",
    "expected_nodes = 2 * (p_h * p_w)\n",
    "assert batch.x.shape[0] == expected_nodes, f\"expected {expected_nodes} nodes in batch, saw {batch.x.shape[0]}\"\n",
    "\n",
    "print(\"\\n✅ DataLoader batching test passed.\\n\")\n",
    "print(\"All patch-related tests completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbde9be",
   "metadata": {},
   "source": [
    "### 3) Mean fields checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e3df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_fields(ds):\n",
    "    \"\"\"\n",
    "    Computes the mean fields values over the entire dataset (all simulations, all timesteps).\n",
    "    \"\"\"\n",
    "    mean_density = []\n",
    "    mean_pressure = []\n",
    "    mean_energy = []\n",
    "    mean_momentum = []  # magnitude\n",
    "\n",
    "    for i in range(ds.n_sims):\n",
    "        # load all time possible steps for simulation i\n",
    "        arrs = ds._load_time_window(sim_idx=i, t_idx=0)\n",
    "        mean_density.append(arrs[\"density\"].mean())\n",
    "        mean_pressure.append(arrs[\"pressure\"].mean())\n",
    "        mean_energy.append(arrs[\"energy\"].mean())\n",
    "\n",
    "        # for momentum, compute magnitude first\n",
    "        arrs[\"momentum\"] = np.sqrt((arrs[\"momentum\"]**2).sum(axis=-1))\n",
    "        mean_momentum.append(arrs[\"momentum\"].mean())\n",
    "\n",
    "    # now compute global means\n",
    "    mean_density = sum(mean_density) / ds.n_sims\n",
    "    mean_pressure = sum(mean_pressure) / ds.n_sims\n",
    "    mean_energy = sum(mean_energy) / ds.n_sims\n",
    "    mean_momentum = sum(mean_momentum) / ds.n_sims\n",
    "\n",
    "    return mean_density, mean_pressure, mean_energy, mean_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f65daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EulerPeriodicDataset: using full-grid samples (512x512), this is large (262144 nodes). Consider patching.\n",
      "EulerPeriodicDataset: using full-grid samples (512x512), this is large (262144 nodes). Consider patching.\n",
      "EulerPeriodicDataset: using full-grid samples (512x512), this is large (262144 nodes). Consider patching.\n",
      "Train means (density, pressure, energy, momentum): (0.9299198387563229, 0.9002689383178949, 2.459686482846737, 0.5267369353398681)\n",
      "Valid means (density, pressure, energy, momentum): (0.9133071875572205, 0.8708313792943955, 2.3710775804519653, 0.4901703608036041)\n",
      "Test means (density, pressure, energy, momentum): (0.8470769155025483, 0.7551606976985932, 2.0858439445495605, 0.48677064090967176)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/work/imos/datasets/euler_multi_quadrants_periodicBC/data/train/euler_multi_quadrants_periodicBC_gamma_1.4_Dry_air_20.hdf5\"\n",
    "valid_path = \"/work/imos/datasets/euler_multi_quadrants_periodicBC/data/valid/euler_multi_quadrants_periodicBC_gamma_1.4_Dry_air_20.hdf5\"\n",
    "test_path = \"/work/imos/datasets/euler_multi_quadrants_periodicBC/data/test/euler_multi_quadrants_periodicBC_gamma_1.4_Dry_air_20.hdf5\"\n",
    "\n",
    "train_ds = EulerPeriodicDataset(train_path, stats_path=stats_path, time_window=1, patch_size=None, normalize=True)\n",
    "valid_ds = EulerPeriodicDataset(valid_path, stats_path=stats_path, time_window=1, patch_size=None, normalize=True)\n",
    "test_ds = EulerPeriodicDataset(test_path, stats_path=stats_path, time_window=1, patch_size=None, normalize=True)\n",
    "\n",
    "# compute mean fields for each split\n",
    "train_means = compute_mean_fields(train_ds)\n",
    "valid_means = compute_mean_fields(valid_ds)\n",
    "test_means = compute_mean_fields(test_ds)\n",
    "\n",
    "print(\"Train means (density, pressure, energy, momentum):\", train_means)\n",
    "print(\"Valid means (density, pressure, energy, momentum):\", valid_means)\n",
    "print(\"Test means (density, pressure, energy, momentum):\", test_means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "me402_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
